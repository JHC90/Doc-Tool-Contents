{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\'\\'\\n{\\n\"title\": \"15_CreateLocaInfoDF\",\\n\"keywords\": \"15_CreateLocaInfoDF, CreateLocalInfo\",\\n\"categories\": \"\",\\n\"description\": \"Hier die Implementierungsnotizen zu der Erstellung der Info-Datei\",\\n\"level\": \"120\",\\n\"pageID\": \"07112020200718-15_CreateLocaInfoDF\"\\n}\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "'''''\n",
    "{\n",
    "\"title\": \"15_CreateLocaInfoDF\",\n",
    "\"keywords\": \"15_CreateLocaInfoDF, CreateLocalInfo\",\n",
    "\"categories\": \"\",\n",
    "\"description\": \"Hier die Implementierungsnotizen zu der Erstellung der Info-Datei\",\n",
    "\"level\": \"120\",\n",
    "\"pageID\": \"07112020200718-15_CreateLocaInfoDF\"\n",
    "}\n",
    "'''''"
   ]
  },
  {
   "source": [
    "<h1>Erstellen einer lokalen Info-Datei</h1>\n",
    "\n",
    "Dev-ID: 15_CreateLocaInfoDF\n",
    "\n",
    "# Ziel \n",
    "Mit diesem Skript soll eine lokale Info-Datei im CSV Format enstehen, welche als weiter führende Grundlage für die bessere Struktuierung meiner Website dienen soll. Konkret soll ein Pandas-DF entstehen und lokal gespeichert werden welche folgende Informationen zu jedem HTML-File enthält:\n",
    "\n",
    "- [x]  pageid\n",
    "- [x]  Absoluter Pfad lokal\n",
    "- [x]  Relativer Pfad Remote\n",
    "- [x]  FielCreationDate\n",
    "- [x]  FileModifiedDate\n",
    "- [x]  FileSize\n",
    "- [x]  level für die Hierarchie\n",
    "- [x]  Keywords = Tags\n",
    "- [x]  categories=Manuell\n",
    "- [x]  description\n",
    "- [x]  categoriesList = Automatisch von Directory Struktuierung\n",
    "- [x]  section = höchste Categorie\n",
    "- [x]  sectionPathAbsolute\n",
    "- [x]  sectionPathRelative\n",
    "- [x]  Remote-Adresse = webadresse der Seite\n",
    "- [x]  Vorgelagerter Page-ID = File das im gleichen Ordner liegt aber ein kleineres Level hat\n",
    "- [x]  nachgelagerte Page-ID = File das im gleichen Ordner liegt aber ein größeres Level hat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Vorbedingung\n",
    "- Es müssen die Content-Seiten mit einem Frame-Matter ausgestattet sein und dort müssen folgende Informationen \n",
    "    - gepflegt sein:\n",
    "        - pageID\n",
    "        - level\n",
    "\n",
    "# Anschluss\n",
    "- Es müssen die Content-Seiten mit einem Frame-Matter ausgestattet sein und dort müssen folgende Informationen \n",
    "    - gepflegt sein:\n",
    "        - pageID\n",
    "        - level\n",
    "\n",
    "# Technologien\n",
    "- Python\n",
    "\n",
    "# Status der Idee\n",
    "- [x]  Die Iddee exisitiert & Die Ideenentwicklung wurde gestarte\n",
    "- [x]  Implementierung und die Technologie bekannt & dokumentiert\n",
    "- [x]  Git Checkout-Developmentbranch \n",
    "- [x]  Implementierung der Technologie in diesem Notebook\n",
    "- [x]  Implementierung der Technologie in den Produktivbereich = *.py Erstellt und in den Publish Prozess implementiert\n",
    "- [x]  Test Local \n",
    "- [x]  Test Remote \n",
    "- [x]  Idee abgeschlossens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Umsetzung\n",
    "Ich iterier hierbei durch das \"content\", da hierbei weniger Transfomrationen ausgeführt werden müssen und die resultierend Info dennoch gleich ist."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from markdown2 import markdown \n",
    "import re\n",
    "import json\n",
    "from json import load\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ErrorMessage=\"\"\n",
    "dir_path = \"C:/DocTool/\"\n",
    "completeList = []\n",
    "for root, dirs, files in os.walk(dir_path+\"content/\"):\n",
    "    for file in files:\n",
    "        currentRow=[]\n",
    "        if file.endswith(\".md\"):\n",
    "            sourceAbsolute = (os.path.join(root, file)).replace(\"\\\\\", \"/\")\n",
    "            sourceRelative = sourceAbsolute.replace(\"C:/DocTool/content\", \"\")\n",
    "            fileCreationTime = time.ctime(os.path.getmtime(sourceAbsolute))\n",
    "            fileLastModifiedTime = time.ctime(os.path.getctime(sourceAbsolute))\n",
    "            filesize = os.path.getsize(sourceAbsolute)\n",
    "\n",
    "            with open(sourceAbsolute, encoding=\"utf8\") as markdown_file:\n",
    "                    article = markdown(\n",
    "                        markdown_file.read())\n",
    "                    \n",
    "                    metadata = {}\n",
    "                    if(\"'''''\" in article):\n",
    "                        splited = re.split(\"'''''\", article)\n",
    "                        metadata = (splited[1])\n",
    "                        metadata = metadata.replace(\"<p>\", \"\")\n",
    "                        metadata = metadata.replace(\"</p>\", \"\")\n",
    "                        metadata = metadata.strip()\n",
    "                        metadata=json.loads(metadata)\n",
    "                        article = splited[2]\n",
    "            try:\n",
    "                pageID=metadata[\"pageID\"]\n",
    "            except:\n",
    "                pageID=\"\"\n",
    "                ErrorMessage = ErrorMessage + \"Die Website: \\n\" + str(sourceAbsolute)+ \"\\nhat keine Page-ID \\n\\n\"\n",
    "            \n",
    "            try:\n",
    "                keywords=metadata[\"keywords\"]\n",
    "            except:\n",
    "                keywords=\"\"\n",
    "                ErrorMessage = ErrorMessage + \"Die Website: \\n\" + str(sourceAbsolute)+ \"\\nhat keine keywords \\n\\n\"\n",
    "\n",
    "            try:\n",
    "                categories=metadata[\"categories\"]\n",
    "            except:\n",
    "                categories=\"\"\n",
    "                ErrorMessage = ErrorMessage + \"Die Website: \\n\" + str(sourceAbsolute)+ \"\\nhat keine categories \\n\\n\"\n",
    "\n",
    "            try:\n",
    "                level=metadata[\"level\"]\n",
    "            except:\n",
    "                level=\"\"\n",
    "                ErrorMessage = ErrorMessage + \"Die Website: \\n\" + str(sourceAbsolute)+ \"\\nhat keine level \\n\\n\"\n",
    "\n",
    "            try:\n",
    "                description=metadata[\"description\"]\n",
    "            except:\n",
    "                description=\"\"\n",
    "                ErrorMessage = ErrorMessage + \"Die Website: \\n\" + str(sourceAbsolute)+ \"\\nhat keine description \\n\\n\"\n",
    "\n",
    "\n",
    "            currentRow.append(pageID)\n",
    "            currentRow.append(sourceAbsolute)\n",
    "            currentRow.append(sourceRelative)\n",
    "            currentRow.append(fileCreationTime)\n",
    "            currentRow.append(fileLastModifiedTime)\n",
    "            currentRow.append(filesize)\n",
    "            currentRow.append(level)\n",
    "            currentRow.append(keywords)\n",
    "            currentRow.append(categories)\n",
    "            currentRow.append(description)\n",
    "            completeList.append(currentRow)\n",
    "\n",
    "            # Ablegen in df\n",
    "\n",
    "\n",
    "file = open(\"./ErrorList-CreateLocalInfoFile.txt\", \"w\", encoding=\"utf-8\")\n",
    "file.write(ErrorMessage)\n",
    "file.close()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrungCategoriesList(x):\n",
    "    '''\n",
    "    Extrahiere die Kategorie Informaitonen vondem pfad und gebe eine Liste zurück\n",
    "    '''\n",
    "    x = x.replace(\"C:/DocTool/content/\", \"\")\n",
    "    x = re.split(\"/\", x)[:-1]\n",
    "    return(x)\n",
    "\n",
    "def returnWebAdresse(x):\n",
    "    '''\n",
    "    Extrahiere die Pfade, sodass die Webadresse ableitbar ist\n",
    "    '''\n",
    "    x = x.replace(\"C:/DocTool/content/\", \"https://jhc90.github.io/\")\n",
    "    x = x.replace(\".md\", \".html\")\n",
    "    return(x)\n",
    "\n",
    "def retrunSection(x):\n",
    "    '''\n",
    "    Extrahiere die Pfade, sodass die Webadresse ableitbar ist\n",
    "    '''\n",
    "    if(len(x) == 0):\n",
    "        x = x\n",
    "    else:\n",
    "        x = x[-1]\n",
    "    return(x)\n",
    "\n",
    "def transformCSVsToList(x):\n",
    "    '''\n",
    "    Extrahiere die Pfade, sodass die Webadresse ableitbar ist\n",
    "    '''\n",
    "    x = re.split(\",\", x)\n",
    "    return(x)\n",
    "\n",
    "def returnSectionPathAbsolute(x):\n",
    "    '''\n",
    "    Extrahiere die absoluten Pfade für die Sections\n",
    "    '''\n",
    "    x = re.split(\"/\", x)[:-1]\n",
    "    y=\"\"\n",
    "    for element in x:\n",
    "        y = y + element + \"/\"\n",
    "    x = y\n",
    "    return(x)\n",
    "\n",
    "def returnSectionPathRelative(x):\n",
    "    '''\n",
    "    Extrahiere die absoluten Pfade für die Sections\n",
    "    '''\n",
    "    x = x.replace(\"C:/DocTool/content\", \"\")\n",
    "    if(x == \"\"):\n",
    "        x = \"/\"\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels =[\"pageid\", \"fileNameAbsolut\", \"fileNameRelative\", \"fileLastModifiedTime\", \"fileCreationTime\", \"fileSizeInBytes\", \"level\", \"keywords\", \"categories\", \"description\" ]\n",
    "\n",
    "DF_MetaData = pd.DataFrame(data=completeList)\n",
    "DF_MetaData.columns=labels\n",
    "DF_MetaData['keywords'] = DF_MetaData['keywords'].apply(transformCSVsToList)\n",
    "DF_MetaData['categories'] = DF_MetaData['categories'].apply(transformCSVsToList)\n",
    "DF_MetaData['categoriesList'] = DF_MetaData['fileNameAbsolut'].apply(retrungCategoriesList)\n",
    "DF_MetaData['section'] = DF_MetaData['categoriesList'].apply(retrunSection)\n",
    "DF_MetaData['sectionPathAbsoulte'] = DF_MetaData['fileNameAbsolut'].apply(returnSectionPathAbsolute)\n",
    "DF_MetaData['sectionPathRelative'] = DF_MetaData['sectionPathAbsoulte'].apply(returnSectionPathRelative)\n",
    "DF_MetaData['webadress'] = DF_MetaData['fileNameAbsolut'].apply(returnWebAdresse)\n",
    "DF_MetaData['vorgelagerteSectionPage'] = \"\"\n",
    "DF_MetaData['nachgelagerteSectionPage'] = \"\"\n",
    "DF_MetaData['sectionIndex'] = \"https://jhc90.github.io/index.html\"\n",
    "\n",
    "\n",
    "# in diesem block werden nun die Level ausgelesen und in eine Reihenfolge gebracht, sodass die Sequent der Files angepasst ist\n",
    "# Das ist wichtig für die vor und nachgelagerten Dateien für die Sections.\n",
    "# DF_MetaData.head()\n",
    "uniqueSectionPathes = DF_MetaData.sectionPathRelative.unique()\n",
    "\n",
    "\n",
    "for element in uniqueSectionPathes:\n",
    "    currentDF  = DF_MetaData.loc[DF_MetaData['sectionPathRelative'] == element]\n",
    "    #print(currentDF.shape) => shape 12\n",
    "    currentDFsorted = currentDF.sort_values(by='level')\n",
    "    #print(currentDFsorted.shape)=> shape 12\n",
    "    \n",
    "    currentDFsorted = currentDFsorted.reset_index()\n",
    "    currentDFsorted['level'] = currentDFsorted.index\n",
    "    currentDFsorted = currentDFsorted.drop('index', axis=1)\n",
    "    currentDFsorted['vorgelagerteSectionPage'] = currentDFsorted['pageid'].shift(periods=1)\n",
    "    currentDFsorted['nachgelagerteSectionPage'] = currentDFsorted['pageid'].shift(periods=-1)\n",
    "   \n",
    "    DF_MetaData = DF_MetaData.append(currentDFsorted)\n",
    "    DF_MetaData = DF_MetaData.drop_duplicates(subset=['fileNameAbsolut'], keep='last')\n",
    "    \n",
    "#print(DF_MetaData[['fileNameAbsolut', 'vorgelagerteSectionPage', 'nachgelagerteSectionPage']].head(50))\n",
    "#DF_check = DF_MetaData[['fileNameAbsolut', 'sectionPathAbsoulte','vorgelagerteSectionPage', 'nachgelagerteSectionPage']]\n",
    "#DF_check.to_csv('./ExcelCheck.csv',index=False)\n",
    "\n",
    "# Speicher DF als CV lokal\n",
    "\n",
    "DF_MetaData.to_csv('C:/DocTool/DocToolMaintainingScripts/SiteMetaInfos.csv',index=False)"
   ]
  }
 ]
}